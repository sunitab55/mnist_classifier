{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data is an instance of the MNIST class and is not a tensor\n",
    "train_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data.data is the actual data tensor with the images\n",
    "# train_data.data.shape also gives the same result\n",
    "train_data.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we use the DataLoader to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loaders = {\n",
    "    \"train\": DataLoader(train_data,\n",
    "                        batch_size=99, \n",
    "                        shuffle=True, \n",
    "                        num_workers=1),\n",
    "    \"test\": DataLoader(test_data, \n",
    "                       batch_size=99, \n",
    "                       shuffle=True, \n",
    "                       num_workers=1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Convolutional Layer 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,\n",
    "                               out_channels=10,\n",
    "                               kernel_size=5,\n",
    "                               stride=1)\n",
    "        # Convolutional Layer 2\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5, 1)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        # Fully Connected Layer 1\n",
    "        self.fc1 = nn.Linear(in_features=20*4*4, out_features=50)\n",
    "        self.fc2 = nn.Linear(in_features=50, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use GPU for training if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders[\"train\"]):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(loaders[\"train\"].dataset),\n",
    "                100. * batch_idx / len(loaders[\"train\"]), loss.item()))\n",
    "            \n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders[\"test\"]:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders[\"test\"].dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(loaders[\"test\"].dataset),\n",
    "        100. * correct / len(loaders[\"test\"].dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.301358\n",
      "Train Epoch: 1 [990/60000 (2%)]\tLoss: 2.299943\n",
      "Train Epoch: 1 [1980/60000 (3%)]\tLoss: 2.292847\n",
      "Train Epoch: 1 [2970/60000 (5%)]\tLoss: 2.265851\n",
      "Train Epoch: 1 [3960/60000 (7%)]\tLoss: 2.112869\n",
      "Train Epoch: 1 [4950/60000 (8%)]\tLoss: 2.014577\n",
      "Train Epoch: 1 [5940/60000 (10%)]\tLoss: 1.967999\n",
      "Train Epoch: 1 [6930/60000 (12%)]\tLoss: 1.991625\n",
      "Train Epoch: 1 [7920/60000 (13%)]\tLoss: 1.862885\n",
      "Train Epoch: 1 [8910/60000 (15%)]\tLoss: 1.953652\n",
      "Train Epoch: 1 [9900/60000 (16%)]\tLoss: 1.937257\n",
      "Train Epoch: 1 [10890/60000 (18%)]\tLoss: 1.855459\n",
      "Train Epoch: 1 [11880/60000 (20%)]\tLoss: 1.921089\n",
      "Train Epoch: 1 [12870/60000 (21%)]\tLoss: 1.790385\n",
      "Train Epoch: 1 [13860/60000 (23%)]\tLoss: 1.823493\n",
      "Train Epoch: 1 [14850/60000 (25%)]\tLoss: 1.867862\n",
      "Train Epoch: 1 [15840/60000 (26%)]\tLoss: 1.865422\n",
      "Train Epoch: 1 [16830/60000 (28%)]\tLoss: 1.825123\n",
      "Train Epoch: 1 [17820/60000 (30%)]\tLoss: 1.821961\n",
      "Train Epoch: 1 [18810/60000 (31%)]\tLoss: 1.678570\n",
      "Train Epoch: 1 [19800/60000 (33%)]\tLoss: 1.726447\n",
      "Train Epoch: 1 [20790/60000 (35%)]\tLoss: 1.756901\n",
      "Train Epoch: 1 [21780/60000 (36%)]\tLoss: 1.705597\n",
      "Train Epoch: 1 [22770/60000 (38%)]\tLoss: 1.711038\n",
      "Train Epoch: 1 [23760/60000 (40%)]\tLoss: 1.723768\n",
      "Train Epoch: 1 [24750/60000 (41%)]\tLoss: 1.672969\n",
      "Train Epoch: 1 [25740/60000 (43%)]\tLoss: 1.704279\n",
      "Train Epoch: 1 [26730/60000 (44%)]\tLoss: 1.724101\n",
      "Train Epoch: 1 [27720/60000 (46%)]\tLoss: 1.693062\n",
      "Train Epoch: 1 [28710/60000 (48%)]\tLoss: 1.709604\n",
      "Train Epoch: 1 [29700/60000 (49%)]\tLoss: 1.673841\n",
      "Train Epoch: 1 [30690/60000 (51%)]\tLoss: 1.693974\n",
      "Train Epoch: 1 [31680/60000 (53%)]\tLoss: 1.667865\n",
      "Train Epoch: 1 [32670/60000 (54%)]\tLoss: 1.644590\n",
      "Train Epoch: 1 [33660/60000 (56%)]\tLoss: 1.646025\n",
      "Train Epoch: 1 [34650/60000 (58%)]\tLoss: 1.679549\n",
      "Train Epoch: 1 [35640/60000 (59%)]\tLoss: 1.667325\n",
      "Train Epoch: 1 [36630/60000 (61%)]\tLoss: 1.709300\n",
      "Train Epoch: 1 [37620/60000 (63%)]\tLoss: 1.691998\n",
      "Train Epoch: 1 [38610/60000 (64%)]\tLoss: 1.658244\n",
      "Train Epoch: 1 [39600/60000 (66%)]\tLoss: 1.726215\n",
      "Train Epoch: 1 [40590/60000 (68%)]\tLoss: 1.605899\n",
      "Train Epoch: 1 [41580/60000 (69%)]\tLoss: 1.626758\n",
      "Train Epoch: 1 [42570/60000 (71%)]\tLoss: 1.668731\n",
      "Train Epoch: 1 [43560/60000 (72%)]\tLoss: 1.653455\n",
      "Train Epoch: 1 [44550/60000 (74%)]\tLoss: 1.620027\n",
      "Train Epoch: 1 [45540/60000 (76%)]\tLoss: 1.600102\n",
      "Train Epoch: 1 [46530/60000 (77%)]\tLoss: 1.638041\n",
      "Train Epoch: 1 [47520/60000 (79%)]\tLoss: 1.673139\n",
      "Train Epoch: 1 [48510/60000 (81%)]\tLoss: 1.641623\n",
      "Train Epoch: 1 [49500/60000 (82%)]\tLoss: 1.617939\n",
      "Train Epoch: 1 [50490/60000 (84%)]\tLoss: 1.640920\n",
      "Train Epoch: 1 [51480/60000 (86%)]\tLoss: 1.645111\n",
      "Train Epoch: 1 [52470/60000 (87%)]\tLoss: 1.632592\n",
      "Train Epoch: 1 [53460/60000 (89%)]\tLoss: 1.581542\n",
      "Train Epoch: 1 [54450/60000 (91%)]\tLoss: 1.575001\n",
      "Train Epoch: 1 [55440/60000 (92%)]\tLoss: 1.675387\n",
      "Train Epoch: 1 [56430/60000 (94%)]\tLoss: 1.650827\n",
      "Train Epoch: 1 [57420/60000 (96%)]\tLoss: 1.592760\n",
      "Train Epoch: 1 [58410/60000 (97%)]\tLoss: 1.603433\n",
      "Train Epoch: 1 [59400/60000 (99%)]\tLoss: 1.655498\n",
      "\n",
      "Test set: Average loss: 0.0158, Accuracy: 9263/10000 (93%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.664810\n",
      "Train Epoch: 2 [990/60000 (2%)]\tLoss: 1.580024\n",
      "Train Epoch: 2 [1980/60000 (3%)]\tLoss: 1.663347\n",
      "Train Epoch: 2 [2970/60000 (5%)]\tLoss: 1.608753\n",
      "Train Epoch: 2 [3960/60000 (7%)]\tLoss: 1.575932\n",
      "Train Epoch: 2 [4950/60000 (8%)]\tLoss: 1.619223\n",
      "Train Epoch: 2 [5940/60000 (10%)]\tLoss: 1.588234\n",
      "Train Epoch: 2 [6930/60000 (12%)]\tLoss: 1.609662\n",
      "Train Epoch: 2 [7920/60000 (13%)]\tLoss: 1.612777\n",
      "Train Epoch: 2 [8910/60000 (15%)]\tLoss: 1.604560\n",
      "Train Epoch: 2 [9900/60000 (16%)]\tLoss: 1.603292\n",
      "Train Epoch: 2 [10890/60000 (18%)]\tLoss: 1.575799\n",
      "Train Epoch: 2 [11880/60000 (20%)]\tLoss: 1.566699\n",
      "Train Epoch: 2 [12870/60000 (21%)]\tLoss: 1.671287\n",
      "Train Epoch: 2 [13860/60000 (23%)]\tLoss: 1.630877\n",
      "Train Epoch: 2 [14850/60000 (25%)]\tLoss: 1.635737\n",
      "Train Epoch: 2 [15840/60000 (26%)]\tLoss: 1.586465\n",
      "Train Epoch: 2 [16830/60000 (28%)]\tLoss: 1.585266\n",
      "Train Epoch: 2 [17820/60000 (30%)]\tLoss: 1.615945\n",
      "Train Epoch: 2 [18810/60000 (31%)]\tLoss: 1.667526\n",
      "Train Epoch: 2 [19800/60000 (33%)]\tLoss: 1.563715\n",
      "Train Epoch: 2 [20790/60000 (35%)]\tLoss: 1.570843\n",
      "Train Epoch: 2 [21780/60000 (36%)]\tLoss: 1.656130\n",
      "Train Epoch: 2 [22770/60000 (38%)]\tLoss: 1.596202\n",
      "Train Epoch: 2 [23760/60000 (40%)]\tLoss: 1.619996\n",
      "Train Epoch: 2 [24750/60000 (41%)]\tLoss: 1.582632\n",
      "Train Epoch: 2 [25740/60000 (43%)]\tLoss: 1.603140\n",
      "Train Epoch: 2 [26730/60000 (44%)]\tLoss: 1.584095\n",
      "Train Epoch: 2 [27720/60000 (46%)]\tLoss: 1.645885\n",
      "Train Epoch: 2 [28710/60000 (48%)]\tLoss: 1.598018\n",
      "Train Epoch: 2 [29700/60000 (49%)]\tLoss: 1.587989\n",
      "Train Epoch: 2 [30690/60000 (51%)]\tLoss: 1.648494\n",
      "Train Epoch: 2 [31680/60000 (53%)]\tLoss: 1.629341\n",
      "Train Epoch: 2 [32670/60000 (54%)]\tLoss: 1.533387\n",
      "Train Epoch: 2 [33660/60000 (56%)]\tLoss: 1.613873\n",
      "Train Epoch: 2 [34650/60000 (58%)]\tLoss: 1.605236\n",
      "Train Epoch: 2 [35640/60000 (59%)]\tLoss: 1.570770\n",
      "Train Epoch: 2 [36630/60000 (61%)]\tLoss: 1.585718\n",
      "Train Epoch: 2 [37620/60000 (63%)]\tLoss: 1.606111\n",
      "Train Epoch: 2 [38610/60000 (64%)]\tLoss: 1.595117\n",
      "Train Epoch: 2 [39600/60000 (66%)]\tLoss: 1.599707\n",
      "Train Epoch: 2 [40590/60000 (68%)]\tLoss: 1.605547\n",
      "Train Epoch: 2 [41580/60000 (69%)]\tLoss: 1.635843\n",
      "Train Epoch: 2 [42570/60000 (71%)]\tLoss: 1.609005\n",
      "Train Epoch: 2 [43560/60000 (72%)]\tLoss: 1.565676\n",
      "Train Epoch: 2 [44550/60000 (74%)]\tLoss: 1.570312\n",
      "Train Epoch: 2 [45540/60000 (76%)]\tLoss: 1.615745\n",
      "Train Epoch: 2 [46530/60000 (77%)]\tLoss: 1.616875\n",
      "Train Epoch: 2 [47520/60000 (79%)]\tLoss: 1.569505\n",
      "Train Epoch: 2 [48510/60000 (81%)]\tLoss: 1.575574\n",
      "Train Epoch: 2 [49500/60000 (82%)]\tLoss: 1.623964\n",
      "Train Epoch: 2 [50490/60000 (84%)]\tLoss: 1.640849\n",
      "Train Epoch: 2 [51480/60000 (86%)]\tLoss: 1.623155\n",
      "Train Epoch: 2 [52470/60000 (87%)]\tLoss: 1.562053\n",
      "Train Epoch: 2 [53460/60000 (89%)]\tLoss: 1.596087\n",
      "Train Epoch: 2 [54450/60000 (91%)]\tLoss: 1.557542\n",
      "Train Epoch: 2 [55440/60000 (92%)]\tLoss: 1.630592\n",
      "Train Epoch: 2 [56430/60000 (94%)]\tLoss: 1.602701\n",
      "Train Epoch: 2 [57420/60000 (96%)]\tLoss: 1.615132\n",
      "Train Epoch: 2 [58410/60000 (97%)]\tLoss: 1.561534\n",
      "Train Epoch: 2 [59400/60000 (99%)]\tLoss: 1.559035\n",
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 9444/10000 (94%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.598559\n",
      "Train Epoch: 3 [990/60000 (2%)]\tLoss: 1.542682\n",
      "Train Epoch: 3 [1980/60000 (3%)]\tLoss: 1.554271\n",
      "Train Epoch: 3 [2970/60000 (5%)]\tLoss: 1.581335\n",
      "Train Epoch: 3 [3960/60000 (7%)]\tLoss: 1.598475\n",
      "Train Epoch: 3 [4950/60000 (8%)]\tLoss: 1.560089\n",
      "Train Epoch: 3 [5940/60000 (10%)]\tLoss: 1.618668\n",
      "Train Epoch: 3 [6930/60000 (12%)]\tLoss: 1.619671\n",
      "Train Epoch: 3 [7920/60000 (13%)]\tLoss: 1.611850\n",
      "Train Epoch: 3 [8910/60000 (15%)]\tLoss: 1.541372\n",
      "Train Epoch: 3 [9900/60000 (16%)]\tLoss: 1.594294\n",
      "Train Epoch: 3 [10890/60000 (18%)]\tLoss: 1.565662\n",
      "Train Epoch: 3 [11880/60000 (20%)]\tLoss: 1.578918\n",
      "Train Epoch: 3 [12870/60000 (21%)]\tLoss: 1.589354\n",
      "Train Epoch: 3 [13860/60000 (23%)]\tLoss: 1.552879\n",
      "Train Epoch: 3 [14850/60000 (25%)]\tLoss: 1.552600\n",
      "Train Epoch: 3 [15840/60000 (26%)]\tLoss: 1.593402\n",
      "Train Epoch: 3 [16830/60000 (28%)]\tLoss: 1.563699\n",
      "Train Epoch: 3 [17820/60000 (30%)]\tLoss: 1.605501\n",
      "Train Epoch: 3 [18810/60000 (31%)]\tLoss: 1.569450\n",
      "Train Epoch: 3 [19800/60000 (33%)]\tLoss: 1.540775\n",
      "Train Epoch: 3 [20790/60000 (35%)]\tLoss: 1.587437\n",
      "Train Epoch: 3 [21780/60000 (36%)]\tLoss: 1.544357\n",
      "Train Epoch: 3 [22770/60000 (38%)]\tLoss: 1.586938\n",
      "Train Epoch: 3 [23760/60000 (40%)]\tLoss: 1.566963\n",
      "Train Epoch: 3 [24750/60000 (41%)]\tLoss: 1.526725\n",
      "Train Epoch: 3 [25740/60000 (43%)]\tLoss: 1.569790\n",
      "Train Epoch: 3 [26730/60000 (44%)]\tLoss: 1.536672\n",
      "Train Epoch: 3 [27720/60000 (46%)]\tLoss: 1.601830\n",
      "Train Epoch: 3 [28710/60000 (48%)]\tLoss: 1.589667\n",
      "Train Epoch: 3 [29700/60000 (49%)]\tLoss: 1.590318\n",
      "Train Epoch: 3 [30690/60000 (51%)]\tLoss: 1.605733\n",
      "Train Epoch: 3 [31680/60000 (53%)]\tLoss: 1.542950\n",
      "Train Epoch: 3 [32670/60000 (54%)]\tLoss: 1.547323\n",
      "Train Epoch: 3 [33660/60000 (56%)]\tLoss: 1.573115\n",
      "Train Epoch: 3 [34650/60000 (58%)]\tLoss: 1.614695\n",
      "Train Epoch: 3 [35640/60000 (59%)]\tLoss: 1.621128\n",
      "Train Epoch: 3 [36630/60000 (61%)]\tLoss: 1.553825\n",
      "Train Epoch: 3 [37620/60000 (63%)]\tLoss: 1.569517\n",
      "Train Epoch: 3 [38610/60000 (64%)]\tLoss: 1.563979\n",
      "Train Epoch: 3 [39600/60000 (66%)]\tLoss: 1.612712\n",
      "Train Epoch: 3 [40590/60000 (68%)]\tLoss: 1.546468\n",
      "Train Epoch: 3 [41580/60000 (69%)]\tLoss: 1.559276\n",
      "Train Epoch: 3 [42570/60000 (71%)]\tLoss: 1.554983\n",
      "Train Epoch: 3 [43560/60000 (72%)]\tLoss: 1.591657\n",
      "Train Epoch: 3 [44550/60000 (74%)]\tLoss: 1.535767\n",
      "Train Epoch: 3 [45540/60000 (76%)]\tLoss: 1.564130\n",
      "Train Epoch: 3 [46530/60000 (77%)]\tLoss: 1.528003\n",
      "Train Epoch: 3 [47520/60000 (79%)]\tLoss: 1.534718\n",
      "Train Epoch: 3 [48510/60000 (81%)]\tLoss: 1.573078\n",
      "Train Epoch: 3 [49500/60000 (82%)]\tLoss: 1.605860\n",
      "Train Epoch: 3 [50490/60000 (84%)]\tLoss: 1.542115\n",
      "Train Epoch: 3 [51480/60000 (86%)]\tLoss: 1.582432\n",
      "Train Epoch: 3 [52470/60000 (87%)]\tLoss: 1.568535\n",
      "Train Epoch: 3 [53460/60000 (89%)]\tLoss: 1.594827\n",
      "Train Epoch: 3 [54450/60000 (91%)]\tLoss: 1.516526\n",
      "Train Epoch: 3 [55440/60000 (92%)]\tLoss: 1.598815\n",
      "Train Epoch: 3 [56430/60000 (94%)]\tLoss: 1.539892\n",
      "Train Epoch: 3 [57420/60000 (96%)]\tLoss: 1.538056\n",
      "Train Epoch: 3 [58410/60000 (97%)]\tLoss: 1.544737\n",
      "Train Epoch: 3 [59400/60000 (99%)]\tLoss: 1.578967\n",
      "\n",
      "Test set: Average loss: 0.0154, Accuracy: 9524/10000 (95%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.575821\n",
      "Train Epoch: 4 [990/60000 (2%)]\tLoss: 1.558833\n",
      "Train Epoch: 4 [1980/60000 (3%)]\tLoss: 1.553773\n",
      "Train Epoch: 4 [2970/60000 (5%)]\tLoss: 1.601005\n",
      "Train Epoch: 4 [3960/60000 (7%)]\tLoss: 1.577761\n",
      "Train Epoch: 4 [4950/60000 (8%)]\tLoss: 1.563542\n",
      "Train Epoch: 4 [5940/60000 (10%)]\tLoss: 1.561268\n",
      "Train Epoch: 4 [6930/60000 (12%)]\tLoss: 1.535735\n",
      "Train Epoch: 4 [7920/60000 (13%)]\tLoss: 1.594655\n",
      "Train Epoch: 4 [8910/60000 (15%)]\tLoss: 1.553311\n",
      "Train Epoch: 4 [9900/60000 (16%)]\tLoss: 1.575992\n",
      "Train Epoch: 4 [10890/60000 (18%)]\tLoss: 1.509540\n",
      "Train Epoch: 4 [11880/60000 (20%)]\tLoss: 1.555715\n",
      "Train Epoch: 4 [12870/60000 (21%)]\tLoss: 1.580683\n",
      "Train Epoch: 4 [13860/60000 (23%)]\tLoss: 1.537437\n",
      "Train Epoch: 4 [14850/60000 (25%)]\tLoss: 1.538814\n",
      "Train Epoch: 4 [15840/60000 (26%)]\tLoss: 1.575514\n",
      "Train Epoch: 4 [16830/60000 (28%)]\tLoss: 1.550162\n",
      "Train Epoch: 4 [17820/60000 (30%)]\tLoss: 1.606943\n",
      "Train Epoch: 4 [18810/60000 (31%)]\tLoss: 1.586625\n",
      "Train Epoch: 4 [19800/60000 (33%)]\tLoss: 1.539106\n",
      "Train Epoch: 4 [20790/60000 (35%)]\tLoss: 1.560954\n",
      "Train Epoch: 4 [21780/60000 (36%)]\tLoss: 1.589564\n",
      "Train Epoch: 4 [22770/60000 (38%)]\tLoss: 1.573742\n",
      "Train Epoch: 4 [23760/60000 (40%)]\tLoss: 1.544918\n",
      "Train Epoch: 4 [24750/60000 (41%)]\tLoss: 1.581259\n",
      "Train Epoch: 4 [25740/60000 (43%)]\tLoss: 1.532382\n",
      "Train Epoch: 4 [26730/60000 (44%)]\tLoss: 1.561909\n",
      "Train Epoch: 4 [27720/60000 (46%)]\tLoss: 1.539672\n",
      "Train Epoch: 4 [28710/60000 (48%)]\tLoss: 1.574750\n",
      "Train Epoch: 4 [29700/60000 (49%)]\tLoss: 1.560977\n",
      "Train Epoch: 4 [30690/60000 (51%)]\tLoss: 1.550622\n",
      "Train Epoch: 4 [31680/60000 (53%)]\tLoss: 1.598006\n",
      "Train Epoch: 4 [32670/60000 (54%)]\tLoss: 1.627087\n",
      "Train Epoch: 4 [33660/60000 (56%)]\tLoss: 1.564610\n",
      "Train Epoch: 4 [34650/60000 (58%)]\tLoss: 1.569116\n",
      "Train Epoch: 4 [35640/60000 (59%)]\tLoss: 1.582687\n",
      "Train Epoch: 4 [36630/60000 (61%)]\tLoss: 1.581272\n",
      "Train Epoch: 4 [37620/60000 (63%)]\tLoss: 1.591855\n",
      "Train Epoch: 4 [38610/60000 (64%)]\tLoss: 1.551478\n",
      "Train Epoch: 4 [39600/60000 (66%)]\tLoss: 1.551895\n",
      "Train Epoch: 4 [40590/60000 (68%)]\tLoss: 1.608138\n",
      "Train Epoch: 4 [41580/60000 (69%)]\tLoss: 1.520965\n",
      "Train Epoch: 4 [42570/60000 (71%)]\tLoss: 1.531343\n",
      "Train Epoch: 4 [43560/60000 (72%)]\tLoss: 1.600216\n",
      "Train Epoch: 4 [44550/60000 (74%)]\tLoss: 1.536015\n",
      "Train Epoch: 4 [45540/60000 (76%)]\tLoss: 1.555551\n",
      "Train Epoch: 4 [46530/60000 (77%)]\tLoss: 1.566138\n",
      "Train Epoch: 4 [47520/60000 (79%)]\tLoss: 1.537762\n",
      "Train Epoch: 4 [48510/60000 (81%)]\tLoss: 1.509918\n",
      "Train Epoch: 4 [49500/60000 (82%)]\tLoss: 1.542290\n",
      "Train Epoch: 4 [50490/60000 (84%)]\tLoss: 1.590437\n",
      "Train Epoch: 4 [51480/60000 (86%)]\tLoss: 1.609556\n",
      "Train Epoch: 4 [52470/60000 (87%)]\tLoss: 1.517585\n",
      "Train Epoch: 4 [53460/60000 (89%)]\tLoss: 1.546873\n",
      "Train Epoch: 4 [54450/60000 (91%)]\tLoss: 1.551002\n",
      "Train Epoch: 4 [55440/60000 (92%)]\tLoss: 1.530746\n",
      "Train Epoch: 4 [56430/60000 (94%)]\tLoss: 1.559731\n",
      "Train Epoch: 4 [57420/60000 (96%)]\tLoss: 1.594482\n",
      "Train Epoch: 4 [58410/60000 (97%)]\tLoss: 1.534078\n",
      "Train Epoch: 4 [59400/60000 (99%)]\tLoss: 1.537266\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 9605/10000 (96%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.499045\n",
      "Train Epoch: 5 [990/60000 (2%)]\tLoss: 1.533728\n",
      "Train Epoch: 5 [1980/60000 (3%)]\tLoss: 1.571692\n",
      "Train Epoch: 5 [2970/60000 (5%)]\tLoss: 1.545903\n",
      "Train Epoch: 5 [3960/60000 (7%)]\tLoss: 1.551458\n",
      "Train Epoch: 5 [4950/60000 (8%)]\tLoss: 1.565731\n",
      "Train Epoch: 5 [5940/60000 (10%)]\tLoss: 1.530470\n",
      "Train Epoch: 5 [6930/60000 (12%)]\tLoss: 1.581764\n",
      "Train Epoch: 5 [7920/60000 (13%)]\tLoss: 1.533939\n",
      "Train Epoch: 5 [8910/60000 (15%)]\tLoss: 1.604279\n",
      "Train Epoch: 5 [9900/60000 (16%)]\tLoss: 1.564272\n",
      "Train Epoch: 5 [10890/60000 (18%)]\tLoss: 1.547611\n",
      "Train Epoch: 5 [11880/60000 (20%)]\tLoss: 1.517020\n",
      "Train Epoch: 5 [12870/60000 (21%)]\tLoss: 1.535880\n",
      "Train Epoch: 5 [13860/60000 (23%)]\tLoss: 1.529731\n",
      "Train Epoch: 5 [14850/60000 (25%)]\tLoss: 1.573349\n",
      "Train Epoch: 5 [15840/60000 (26%)]\tLoss: 1.563001\n",
      "Train Epoch: 5 [16830/60000 (28%)]\tLoss: 1.535161\n",
      "Train Epoch: 5 [17820/60000 (30%)]\tLoss: 1.580174\n",
      "Train Epoch: 5 [18810/60000 (31%)]\tLoss: 1.543882\n",
      "Train Epoch: 5 [19800/60000 (33%)]\tLoss: 1.562856\n",
      "Train Epoch: 5 [20790/60000 (35%)]\tLoss: 1.575217\n",
      "Train Epoch: 5 [21780/60000 (36%)]\tLoss: 1.554908\n",
      "Train Epoch: 5 [22770/60000 (38%)]\tLoss: 1.508673\n",
      "Train Epoch: 5 [23760/60000 (40%)]\tLoss: 1.561154\n",
      "Train Epoch: 5 [24750/60000 (41%)]\tLoss: 1.609038\n",
      "Train Epoch: 5 [25740/60000 (43%)]\tLoss: 1.521107\n",
      "Train Epoch: 5 [26730/60000 (44%)]\tLoss: 1.563497\n",
      "Train Epoch: 5 [27720/60000 (46%)]\tLoss: 1.577965\n",
      "Train Epoch: 5 [28710/60000 (48%)]\tLoss: 1.507873\n",
      "Train Epoch: 5 [29700/60000 (49%)]\tLoss: 1.532745\n",
      "Train Epoch: 5 [30690/60000 (51%)]\tLoss: 1.564408\n",
      "Train Epoch: 5 [31680/60000 (53%)]\tLoss: 1.535489\n",
      "Train Epoch: 5 [32670/60000 (54%)]\tLoss: 1.631757\n",
      "Train Epoch: 5 [33660/60000 (56%)]\tLoss: 1.546438\n",
      "Train Epoch: 5 [34650/60000 (58%)]\tLoss: 1.614954\n",
      "Train Epoch: 5 [35640/60000 (59%)]\tLoss: 1.546968\n",
      "Train Epoch: 5 [36630/60000 (61%)]\tLoss: 1.511458\n",
      "Train Epoch: 5 [37620/60000 (63%)]\tLoss: 1.554040\n",
      "Train Epoch: 5 [38610/60000 (64%)]\tLoss: 1.489315\n",
      "Train Epoch: 5 [39600/60000 (66%)]\tLoss: 1.522729\n",
      "Train Epoch: 5 [40590/60000 (68%)]\tLoss: 1.525904\n",
      "Train Epoch: 5 [41580/60000 (69%)]\tLoss: 1.600355\n",
      "Train Epoch: 5 [42570/60000 (71%)]\tLoss: 1.595161\n",
      "Train Epoch: 5 [43560/60000 (72%)]\tLoss: 1.561290\n",
      "Train Epoch: 5 [44550/60000 (74%)]\tLoss: 1.493365\n",
      "Train Epoch: 5 [45540/60000 (76%)]\tLoss: 1.501677\n",
      "Train Epoch: 5 [46530/60000 (77%)]\tLoss: 1.581549\n",
      "Train Epoch: 5 [47520/60000 (79%)]\tLoss: 1.566118\n",
      "Train Epoch: 5 [48510/60000 (81%)]\tLoss: 1.607861\n",
      "Train Epoch: 5 [49500/60000 (82%)]\tLoss: 1.531606\n",
      "Train Epoch: 5 [50490/60000 (84%)]\tLoss: 1.531223\n",
      "Train Epoch: 5 [51480/60000 (86%)]\tLoss: 1.534471\n",
      "Train Epoch: 5 [52470/60000 (87%)]\tLoss: 1.571950\n",
      "Train Epoch: 5 [53460/60000 (89%)]\tLoss: 1.538085\n",
      "Train Epoch: 5 [54450/60000 (91%)]\tLoss: 1.547206\n",
      "Train Epoch: 5 [55440/60000 (92%)]\tLoss: 1.553349\n",
      "Train Epoch: 5 [56430/60000 (94%)]\tLoss: 1.509728\n",
      "Train Epoch: 5 [57420/60000 (96%)]\tLoss: 1.578336\n",
      "Train Epoch: 5 [58410/60000 (97%)]\tLoss: 1.555277\n",
      "Train Epoch: 5 [59400/60000 (99%)]\tLoss: 1.521222\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 9609/10000 (96%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.511633\n",
      "Train Epoch: 6 [990/60000 (2%)]\tLoss: 1.545038\n",
      "Train Epoch: 6 [1980/60000 (3%)]\tLoss: 1.538580\n",
      "Train Epoch: 6 [2970/60000 (5%)]\tLoss: 1.580854\n",
      "Train Epoch: 6 [3960/60000 (7%)]\tLoss: 1.559385\n",
      "Train Epoch: 6 [4950/60000 (8%)]\tLoss: 1.540143\n",
      "Train Epoch: 6 [5940/60000 (10%)]\tLoss: 1.545084\n",
      "Train Epoch: 6 [6930/60000 (12%)]\tLoss: 1.581458\n",
      "Train Epoch: 6 [7920/60000 (13%)]\tLoss: 1.554505\n",
      "Train Epoch: 6 [8910/60000 (15%)]\tLoss: 1.503428\n",
      "Train Epoch: 6 [9900/60000 (16%)]\tLoss: 1.566967\n",
      "Train Epoch: 6 [10890/60000 (18%)]\tLoss: 1.543169\n",
      "Train Epoch: 6 [11880/60000 (20%)]\tLoss: 1.540141\n",
      "Train Epoch: 6 [12870/60000 (21%)]\tLoss: 1.582537\n",
      "Train Epoch: 6 [13860/60000 (23%)]\tLoss: 1.528667\n",
      "Train Epoch: 6 [14850/60000 (25%)]\tLoss: 1.498327\n",
      "Train Epoch: 6 [15840/60000 (26%)]\tLoss: 1.547697\n",
      "Train Epoch: 6 [16830/60000 (28%)]\tLoss: 1.546138\n",
      "Train Epoch: 6 [17820/60000 (30%)]\tLoss: 1.550711\n",
      "Train Epoch: 6 [18810/60000 (31%)]\tLoss: 1.562401\n",
      "Train Epoch: 6 [19800/60000 (33%)]\tLoss: 1.539333\n",
      "Train Epoch: 6 [20790/60000 (35%)]\tLoss: 1.561051\n",
      "Train Epoch: 6 [21780/60000 (36%)]\tLoss: 1.565035\n",
      "Train Epoch: 6 [22770/60000 (38%)]\tLoss: 1.595523\n",
      "Train Epoch: 6 [23760/60000 (40%)]\tLoss: 1.534510\n",
      "Train Epoch: 6 [24750/60000 (41%)]\tLoss: 1.518970\n",
      "Train Epoch: 6 [25740/60000 (43%)]\tLoss: 1.597335\n",
      "Train Epoch: 6 [26730/60000 (44%)]\tLoss: 1.506745\n",
      "Train Epoch: 6 [27720/60000 (46%)]\tLoss: 1.570872\n",
      "Train Epoch: 6 [28710/60000 (48%)]\tLoss: 1.519891\n",
      "Train Epoch: 6 [29700/60000 (49%)]\tLoss: 1.575171\n",
      "Train Epoch: 6 [30690/60000 (51%)]\tLoss: 1.522291\n",
      "Train Epoch: 6 [31680/60000 (53%)]\tLoss: 1.531220\n",
      "Train Epoch: 6 [32670/60000 (54%)]\tLoss: 1.539935\n",
      "Train Epoch: 6 [33660/60000 (56%)]\tLoss: 1.556573\n",
      "Train Epoch: 6 [34650/60000 (58%)]\tLoss: 1.540771\n",
      "Train Epoch: 6 [35640/60000 (59%)]\tLoss: 1.524836\n",
      "Train Epoch: 6 [36630/60000 (61%)]\tLoss: 1.507983\n",
      "Train Epoch: 6 [37620/60000 (63%)]\tLoss: 1.561183\n",
      "Train Epoch: 6 [38610/60000 (64%)]\tLoss: 1.553942\n",
      "Train Epoch: 6 [39600/60000 (66%)]\tLoss: 1.520366\n",
      "Train Epoch: 6 [40590/60000 (68%)]\tLoss: 1.552240\n",
      "Train Epoch: 6 [41580/60000 (69%)]\tLoss: 1.581462\n",
      "Train Epoch: 6 [42570/60000 (71%)]\tLoss: 1.564156\n",
      "Train Epoch: 6 [43560/60000 (72%)]\tLoss: 1.537208\n",
      "Train Epoch: 6 [44550/60000 (74%)]\tLoss: 1.528724\n",
      "Train Epoch: 6 [45540/60000 (76%)]\tLoss: 1.539174\n",
      "Train Epoch: 6 [46530/60000 (77%)]\tLoss: 1.582747\n",
      "Train Epoch: 6 [47520/60000 (79%)]\tLoss: 1.581679\n",
      "Train Epoch: 6 [48510/60000 (81%)]\tLoss: 1.566688\n",
      "Train Epoch: 6 [49500/60000 (82%)]\tLoss: 1.535322\n",
      "Train Epoch: 6 [50490/60000 (84%)]\tLoss: 1.536736\n",
      "Train Epoch: 6 [51480/60000 (86%)]\tLoss: 1.553125\n",
      "Train Epoch: 6 [52470/60000 (87%)]\tLoss: 1.516951\n",
      "Train Epoch: 6 [53460/60000 (89%)]\tLoss: 1.539743\n",
      "Train Epoch: 6 [54450/60000 (91%)]\tLoss: 1.541828\n",
      "Train Epoch: 6 [55440/60000 (92%)]\tLoss: 1.549041\n",
      "Train Epoch: 6 [56430/60000 (94%)]\tLoss: 1.523905\n",
      "Train Epoch: 6 [57420/60000 (96%)]\tLoss: 1.555231\n",
      "Train Epoch: 6 [58410/60000 (97%)]\tLoss: 1.525718\n",
      "Train Epoch: 6 [59400/60000 (99%)]\tLoss: 1.531751\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 9632/10000 (96%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 1.549477\n",
      "Train Epoch: 7 [990/60000 (2%)]\tLoss: 1.571555\n",
      "Train Epoch: 7 [1980/60000 (3%)]\tLoss: 1.516577\n",
      "Train Epoch: 7 [2970/60000 (5%)]\tLoss: 1.550204\n",
      "Train Epoch: 7 [3960/60000 (7%)]\tLoss: 1.575220\n",
      "Train Epoch: 7 [4950/60000 (8%)]\tLoss: 1.571862\n",
      "Train Epoch: 7 [5940/60000 (10%)]\tLoss: 1.544963\n",
      "Train Epoch: 7 [6930/60000 (12%)]\tLoss: 1.550442\n",
      "Train Epoch: 7 [7920/60000 (13%)]\tLoss: 1.557391\n",
      "Train Epoch: 7 [8910/60000 (15%)]\tLoss: 1.574218\n",
      "Train Epoch: 7 [9900/60000 (16%)]\tLoss: 1.546354\n",
      "Train Epoch: 7 [10890/60000 (18%)]\tLoss: 1.537831\n",
      "Train Epoch: 7 [11880/60000 (20%)]\tLoss: 1.613273\n",
      "Train Epoch: 7 [12870/60000 (21%)]\tLoss: 1.577840\n",
      "Train Epoch: 7 [13860/60000 (23%)]\tLoss: 1.566695\n",
      "Train Epoch: 7 [14850/60000 (25%)]\tLoss: 1.514019\n",
      "Train Epoch: 7 [15840/60000 (26%)]\tLoss: 1.540554\n",
      "Train Epoch: 7 [16830/60000 (28%)]\tLoss: 1.560812\n",
      "Train Epoch: 7 [17820/60000 (30%)]\tLoss: 1.539287\n",
      "Train Epoch: 7 [18810/60000 (31%)]\tLoss: 1.582738\n",
      "Train Epoch: 7 [19800/60000 (33%)]\tLoss: 1.566022\n",
      "Train Epoch: 7 [20790/60000 (35%)]\tLoss: 1.524215\n",
      "Train Epoch: 7 [21780/60000 (36%)]\tLoss: 1.512463\n",
      "Train Epoch: 7 [22770/60000 (38%)]\tLoss: 1.534774\n",
      "Train Epoch: 7 [23760/60000 (40%)]\tLoss: 1.571033\n",
      "Train Epoch: 7 [24750/60000 (41%)]\tLoss: 1.560999\n",
      "Train Epoch: 7 [25740/60000 (43%)]\tLoss: 1.503028\n",
      "Train Epoch: 7 [26730/60000 (44%)]\tLoss: 1.537993\n",
      "Train Epoch: 7 [27720/60000 (46%)]\tLoss: 1.566286\n",
      "Train Epoch: 7 [28710/60000 (48%)]\tLoss: 1.550119\n",
      "Train Epoch: 7 [29700/60000 (49%)]\tLoss: 1.567381\n",
      "Train Epoch: 7 [30690/60000 (51%)]\tLoss: 1.544505\n",
      "Train Epoch: 7 [31680/60000 (53%)]\tLoss: 1.554282\n",
      "Train Epoch: 7 [32670/60000 (54%)]\tLoss: 1.564214\n",
      "Train Epoch: 7 [33660/60000 (56%)]\tLoss: 1.525160\n",
      "Train Epoch: 7 [34650/60000 (58%)]\tLoss: 1.509619\n",
      "Train Epoch: 7 [35640/60000 (59%)]\tLoss: 1.524133\n",
      "Train Epoch: 7 [36630/60000 (61%)]\tLoss: 1.537724\n",
      "Train Epoch: 7 [37620/60000 (63%)]\tLoss: 1.512459\n",
      "Train Epoch: 7 [38610/60000 (64%)]\tLoss: 1.538993\n",
      "Train Epoch: 7 [39600/60000 (66%)]\tLoss: 1.536423\n",
      "Train Epoch: 7 [40590/60000 (68%)]\tLoss: 1.605157\n",
      "Train Epoch: 7 [41580/60000 (69%)]\tLoss: 1.530674\n",
      "Train Epoch: 7 [42570/60000 (71%)]\tLoss: 1.584670\n",
      "Train Epoch: 7 [43560/60000 (72%)]\tLoss: 1.538359\n",
      "Train Epoch: 7 [44550/60000 (74%)]\tLoss: 1.528467\n",
      "Train Epoch: 7 [45540/60000 (76%)]\tLoss: 1.571483\n",
      "Train Epoch: 7 [46530/60000 (77%)]\tLoss: 1.526915\n",
      "Train Epoch: 7 [47520/60000 (79%)]\tLoss: 1.535133\n",
      "Train Epoch: 7 [48510/60000 (81%)]\tLoss: 1.501162\n",
      "Train Epoch: 7 [49500/60000 (82%)]\tLoss: 1.513952\n",
      "Train Epoch: 7 [50490/60000 (84%)]\tLoss: 1.563134\n",
      "Train Epoch: 7 [51480/60000 (86%)]\tLoss: 1.516614\n",
      "Train Epoch: 7 [52470/60000 (87%)]\tLoss: 1.557603\n",
      "Train Epoch: 7 [53460/60000 (89%)]\tLoss: 1.557761\n",
      "Train Epoch: 7 [54450/60000 (91%)]\tLoss: 1.511928\n",
      "Train Epoch: 7 [55440/60000 (92%)]\tLoss: 1.547738\n",
      "Train Epoch: 7 [56430/60000 (94%)]\tLoss: 1.500247\n",
      "Train Epoch: 7 [57420/60000 (96%)]\tLoss: 1.540405\n",
      "Train Epoch: 7 [58410/60000 (97%)]\tLoss: 1.536991\n",
      "Train Epoch: 7 [59400/60000 (99%)]\tLoss: 1.534325\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 9673/10000 (97%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 1.518805\n",
      "Train Epoch: 8 [990/60000 (2%)]\tLoss: 1.557686\n",
      "Train Epoch: 8 [1980/60000 (3%)]\tLoss: 1.515653\n",
      "Train Epoch: 8 [2970/60000 (5%)]\tLoss: 1.535057\n",
      "Train Epoch: 8 [3960/60000 (7%)]\tLoss: 1.528181\n",
      "Train Epoch: 8 [4950/60000 (8%)]\tLoss: 1.553827\n",
      "Train Epoch: 8 [5940/60000 (10%)]\tLoss: 1.547257\n",
      "Train Epoch: 8 [6930/60000 (12%)]\tLoss: 1.546217\n",
      "Train Epoch: 8 [7920/60000 (13%)]\tLoss: 1.521992\n",
      "Train Epoch: 8 [8910/60000 (15%)]\tLoss: 1.571557\n",
      "Train Epoch: 8 [9900/60000 (16%)]\tLoss: 1.542584\n",
      "Train Epoch: 8 [10890/60000 (18%)]\tLoss: 1.531772\n",
      "Train Epoch: 8 [11880/60000 (20%)]\tLoss: 1.559194\n",
      "Train Epoch: 8 [12870/60000 (21%)]\tLoss: 1.546537\n",
      "Train Epoch: 8 [13860/60000 (23%)]\tLoss: 1.527889\n",
      "Train Epoch: 8 [14850/60000 (25%)]\tLoss: 1.549377\n",
      "Train Epoch: 8 [15840/60000 (26%)]\tLoss: 1.496136\n",
      "Train Epoch: 8 [16830/60000 (28%)]\tLoss: 1.554049\n",
      "Train Epoch: 8 [17820/60000 (30%)]\tLoss: 1.612170\n",
      "Train Epoch: 8 [18810/60000 (31%)]\tLoss: 1.516282\n",
      "Train Epoch: 8 [19800/60000 (33%)]\tLoss: 1.594466\n",
      "Train Epoch: 8 [20790/60000 (35%)]\tLoss: 1.553445\n",
      "Train Epoch: 8 [21780/60000 (36%)]\tLoss: 1.555500\n",
      "Train Epoch: 8 [22770/60000 (38%)]\tLoss: 1.512059\n",
      "Train Epoch: 8 [23760/60000 (40%)]\tLoss: 1.563738\n",
      "Train Epoch: 8 [24750/60000 (41%)]\tLoss: 1.561382\n",
      "Train Epoch: 8 [25740/60000 (43%)]\tLoss: 1.563267\n",
      "Train Epoch: 8 [26730/60000 (44%)]\tLoss: 1.522153\n",
      "Train Epoch: 8 [27720/60000 (46%)]\tLoss: 1.489630\n",
      "Train Epoch: 8 [28710/60000 (48%)]\tLoss: 1.506811\n",
      "Train Epoch: 8 [29700/60000 (49%)]\tLoss: 1.521923\n",
      "Train Epoch: 8 [30690/60000 (51%)]\tLoss: 1.497805\n",
      "Train Epoch: 8 [31680/60000 (53%)]\tLoss: 1.525344\n",
      "Train Epoch: 8 [32670/60000 (54%)]\tLoss: 1.559935\n",
      "Train Epoch: 8 [33660/60000 (56%)]\tLoss: 1.539873\n",
      "Train Epoch: 8 [34650/60000 (58%)]\tLoss: 1.551576\n",
      "Train Epoch: 8 [35640/60000 (59%)]\tLoss: 1.509996\n",
      "Train Epoch: 8 [36630/60000 (61%)]\tLoss: 1.563562\n",
      "Train Epoch: 8 [37620/60000 (63%)]\tLoss: 1.573558\n",
      "Train Epoch: 8 [38610/60000 (64%)]\tLoss: 1.543168\n",
      "Train Epoch: 8 [39600/60000 (66%)]\tLoss: 1.540865\n",
      "Train Epoch: 8 [40590/60000 (68%)]\tLoss: 1.518112\n",
      "Train Epoch: 8 [41580/60000 (69%)]\tLoss: 1.519161\n",
      "Train Epoch: 8 [42570/60000 (71%)]\tLoss: 1.556426\n",
      "Train Epoch: 8 [43560/60000 (72%)]\tLoss: 1.524647\n",
      "Train Epoch: 8 [44550/60000 (74%)]\tLoss: 1.550830\n",
      "Train Epoch: 8 [45540/60000 (76%)]\tLoss: 1.580171\n",
      "Train Epoch: 8 [46530/60000 (77%)]\tLoss: 1.528281\n",
      "Train Epoch: 8 [47520/60000 (79%)]\tLoss: 1.526969\n",
      "Train Epoch: 8 [48510/60000 (81%)]\tLoss: 1.555701\n",
      "Train Epoch: 8 [49500/60000 (82%)]\tLoss: 1.496856\n",
      "Train Epoch: 8 [50490/60000 (84%)]\tLoss: 1.568909\n",
      "Train Epoch: 8 [51480/60000 (86%)]\tLoss: 1.536477\n",
      "Train Epoch: 8 [52470/60000 (87%)]\tLoss: 1.540042\n",
      "Train Epoch: 8 [53460/60000 (89%)]\tLoss: 1.547608\n",
      "Train Epoch: 8 [54450/60000 (91%)]\tLoss: 1.546328\n",
      "Train Epoch: 8 [55440/60000 (92%)]\tLoss: 1.532621\n",
      "Train Epoch: 8 [56430/60000 (94%)]\tLoss: 1.571838\n",
      "Train Epoch: 8 [57420/60000 (96%)]\tLoss: 1.515663\n",
      "Train Epoch: 8 [58410/60000 (97%)]\tLoss: 1.532637\n",
      "Train Epoch: 8 [59400/60000 (99%)]\tLoss: 1.569130\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 9703/10000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 1.507582\n",
      "Train Epoch: 9 [990/60000 (2%)]\tLoss: 1.484884\n",
      "Train Epoch: 9 [1980/60000 (3%)]\tLoss: 1.514377\n",
      "Train Epoch: 9 [2970/60000 (5%)]\tLoss: 1.535701\n",
      "Train Epoch: 9 [3960/60000 (7%)]\tLoss: 1.558642\n",
      "Train Epoch: 9 [4950/60000 (8%)]\tLoss: 1.562674\n",
      "Train Epoch: 9 [5940/60000 (10%)]\tLoss: 1.541865\n",
      "Train Epoch: 9 [6930/60000 (12%)]\tLoss: 1.522802\n",
      "Train Epoch: 9 [7920/60000 (13%)]\tLoss: 1.507354\n",
      "Train Epoch: 9 [8910/60000 (15%)]\tLoss: 1.541533\n",
      "Train Epoch: 9 [9900/60000 (16%)]\tLoss: 1.514828\n",
      "Train Epoch: 9 [10890/60000 (18%)]\tLoss: 1.542714\n",
      "Train Epoch: 9 [11880/60000 (20%)]\tLoss: 1.544968\n",
      "Train Epoch: 9 [12870/60000 (21%)]\tLoss: 1.535978\n",
      "Train Epoch: 9 [13860/60000 (23%)]\tLoss: 1.548170\n",
      "Train Epoch: 9 [14850/60000 (25%)]\tLoss: 1.544972\n",
      "Train Epoch: 9 [15840/60000 (26%)]\tLoss: 1.519400\n",
      "Train Epoch: 9 [16830/60000 (28%)]\tLoss: 1.536830\n",
      "Train Epoch: 9 [17820/60000 (30%)]\tLoss: 1.540294\n",
      "Train Epoch: 9 [18810/60000 (31%)]\tLoss: 1.536062\n",
      "Train Epoch: 9 [19800/60000 (33%)]\tLoss: 1.513105\n",
      "Train Epoch: 9 [20790/60000 (35%)]\tLoss: 1.539057\n",
      "Train Epoch: 9 [21780/60000 (36%)]\tLoss: 1.528234\n",
      "Train Epoch: 9 [22770/60000 (38%)]\tLoss: 1.537471\n",
      "Train Epoch: 9 [23760/60000 (40%)]\tLoss: 1.586767\n",
      "Train Epoch: 9 [24750/60000 (41%)]\tLoss: 1.581725\n",
      "Train Epoch: 9 [25740/60000 (43%)]\tLoss: 1.516964\n",
      "Train Epoch: 9 [26730/60000 (44%)]\tLoss: 1.533958\n",
      "Train Epoch: 9 [27720/60000 (46%)]\tLoss: 1.527925\n",
      "Train Epoch: 9 [28710/60000 (48%)]\tLoss: 1.543055\n",
      "Train Epoch: 9 [29700/60000 (49%)]\tLoss: 1.505250\n",
      "Train Epoch: 9 [30690/60000 (51%)]\tLoss: 1.527622\n",
      "Train Epoch: 9 [31680/60000 (53%)]\tLoss: 1.478211\n",
      "Train Epoch: 9 [32670/60000 (54%)]\tLoss: 1.518529\n",
      "Train Epoch: 9 [33660/60000 (56%)]\tLoss: 1.569684\n",
      "Train Epoch: 9 [34650/60000 (58%)]\tLoss: 1.513589\n",
      "Train Epoch: 9 [35640/60000 (59%)]\tLoss: 1.526785\n",
      "Train Epoch: 9 [36630/60000 (61%)]\tLoss: 1.521732\n",
      "Train Epoch: 9 [37620/60000 (63%)]\tLoss: 1.549895\n",
      "Train Epoch: 9 [38610/60000 (64%)]\tLoss: 1.516919\n",
      "Train Epoch: 9 [39600/60000 (66%)]\tLoss: 1.550925\n",
      "Train Epoch: 9 [40590/60000 (68%)]\tLoss: 1.542779\n",
      "Train Epoch: 9 [41580/60000 (69%)]\tLoss: 1.564885\n",
      "Train Epoch: 9 [42570/60000 (71%)]\tLoss: 1.519435\n",
      "Train Epoch: 9 [43560/60000 (72%)]\tLoss: 1.482864\n",
      "Train Epoch: 9 [44550/60000 (74%)]\tLoss: 1.521648\n",
      "Train Epoch: 9 [45540/60000 (76%)]\tLoss: 1.520217\n",
      "Train Epoch: 9 [46530/60000 (77%)]\tLoss: 1.537786\n",
      "Train Epoch: 9 [47520/60000 (79%)]\tLoss: 1.547167\n",
      "Train Epoch: 9 [48510/60000 (81%)]\tLoss: 1.590411\n",
      "Train Epoch: 9 [49500/60000 (82%)]\tLoss: 1.555610\n",
      "Train Epoch: 9 [50490/60000 (84%)]\tLoss: 1.536262\n",
      "Train Epoch: 9 [51480/60000 (86%)]\tLoss: 1.553378\n",
      "Train Epoch: 9 [52470/60000 (87%)]\tLoss: 1.513144\n",
      "Train Epoch: 9 [53460/60000 (89%)]\tLoss: 1.516728\n",
      "Train Epoch: 9 [54450/60000 (91%)]\tLoss: 1.530888\n",
      "Train Epoch: 9 [55440/60000 (92%)]\tLoss: 1.523944\n",
      "Train Epoch: 9 [56430/60000 (94%)]\tLoss: 1.519176\n",
      "Train Epoch: 9 [57420/60000 (96%)]\tLoss: 1.522298\n",
      "Train Epoch: 9 [58410/60000 (97%)]\tLoss: 1.527697\n",
      "Train Epoch: 9 [59400/60000 (99%)]\tLoss: 1.525538\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 9718/10000 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 1.520871\n",
      "Train Epoch: 10 [990/60000 (2%)]\tLoss: 1.515966\n",
      "Train Epoch: 10 [1980/60000 (3%)]\tLoss: 1.526521\n",
      "Train Epoch: 10 [2970/60000 (5%)]\tLoss: 1.551559\n",
      "Train Epoch: 10 [3960/60000 (7%)]\tLoss: 1.552117\n",
      "Train Epoch: 10 [4950/60000 (8%)]\tLoss: 1.499759\n",
      "Train Epoch: 10 [5940/60000 (10%)]\tLoss: 1.524127\n",
      "Train Epoch: 10 [6930/60000 (12%)]\tLoss: 1.519953\n",
      "Train Epoch: 10 [7920/60000 (13%)]\tLoss: 1.539665\n",
      "Train Epoch: 10 [8910/60000 (15%)]\tLoss: 1.575791\n",
      "Train Epoch: 10 [9900/60000 (16%)]\tLoss: 1.565153\n",
      "Train Epoch: 10 [10890/60000 (18%)]\tLoss: 1.553484\n",
      "Train Epoch: 10 [11880/60000 (20%)]\tLoss: 1.549804\n",
      "Train Epoch: 10 [12870/60000 (21%)]\tLoss: 1.545976\n",
      "Train Epoch: 10 [13860/60000 (23%)]\tLoss: 1.544705\n",
      "Train Epoch: 10 [14850/60000 (25%)]\tLoss: 1.517651\n",
      "Train Epoch: 10 [15840/60000 (26%)]\tLoss: 1.540747\n",
      "Train Epoch: 10 [16830/60000 (28%)]\tLoss: 1.523626\n",
      "Train Epoch: 10 [17820/60000 (30%)]\tLoss: 1.540596\n",
      "Train Epoch: 10 [18810/60000 (31%)]\tLoss: 1.552160\n",
      "Train Epoch: 10 [19800/60000 (33%)]\tLoss: 1.518698\n",
      "Train Epoch: 10 [20790/60000 (35%)]\tLoss: 1.548193\n",
      "Train Epoch: 10 [21780/60000 (36%)]\tLoss: 1.489972\n",
      "Train Epoch: 10 [22770/60000 (38%)]\tLoss: 1.522406\n",
      "Train Epoch: 10 [23760/60000 (40%)]\tLoss: 1.519765\n",
      "Train Epoch: 10 [24750/60000 (41%)]\tLoss: 1.550239\n",
      "Train Epoch: 10 [25740/60000 (43%)]\tLoss: 1.532940\n",
      "Train Epoch: 10 [26730/60000 (44%)]\tLoss: 1.560207\n",
      "Train Epoch: 10 [27720/60000 (46%)]\tLoss: 1.516668\n",
      "Train Epoch: 10 [28710/60000 (48%)]\tLoss: 1.616080\n",
      "Train Epoch: 10 [29700/60000 (49%)]\tLoss: 1.535645\n",
      "Train Epoch: 10 [30690/60000 (51%)]\tLoss: 1.507471\n",
      "Train Epoch: 10 [31680/60000 (53%)]\tLoss: 1.551672\n",
      "Train Epoch: 10 [32670/60000 (54%)]\tLoss: 1.534343\n",
      "Train Epoch: 10 [33660/60000 (56%)]\tLoss: 1.548541\n",
      "Train Epoch: 10 [34650/60000 (58%)]\tLoss: 1.508766\n",
      "Train Epoch: 10 [35640/60000 (59%)]\tLoss: 1.562716\n",
      "Train Epoch: 10 [36630/60000 (61%)]\tLoss: 1.506180\n",
      "Train Epoch: 10 [37620/60000 (63%)]\tLoss: 1.508618\n",
      "Train Epoch: 10 [38610/60000 (64%)]\tLoss: 1.524939\n",
      "Train Epoch: 10 [39600/60000 (66%)]\tLoss: 1.574561\n",
      "Train Epoch: 10 [40590/60000 (68%)]\tLoss: 1.498126\n",
      "Train Epoch: 10 [41580/60000 (69%)]\tLoss: 1.543022\n",
      "Train Epoch: 10 [42570/60000 (71%)]\tLoss: 1.522882\n",
      "Train Epoch: 10 [43560/60000 (72%)]\tLoss: 1.524592\n",
      "Train Epoch: 10 [44550/60000 (74%)]\tLoss: 1.513448\n",
      "Train Epoch: 10 [45540/60000 (76%)]\tLoss: 1.523284\n",
      "Train Epoch: 10 [46530/60000 (77%)]\tLoss: 1.525784\n",
      "Train Epoch: 10 [47520/60000 (79%)]\tLoss: 1.550496\n",
      "Train Epoch: 10 [48510/60000 (81%)]\tLoss: 1.530987\n",
      "Train Epoch: 10 [49500/60000 (82%)]\tLoss: 1.531916\n",
      "Train Epoch: 10 [50490/60000 (84%)]\tLoss: 1.548309\n",
      "Train Epoch: 10 [51480/60000 (86%)]\tLoss: 1.513009\n",
      "Train Epoch: 10 [52470/60000 (87%)]\tLoss: 1.548950\n",
      "Train Epoch: 10 [53460/60000 (89%)]\tLoss: 1.496314\n",
      "Train Epoch: 10 [54450/60000 (91%)]\tLoss: 1.574052\n",
      "Train Epoch: 10 [55440/60000 (92%)]\tLoss: 1.512239\n",
      "Train Epoch: 10 [56430/60000 (94%)]\tLoss: 1.502889\n",
      "Train Epoch: 10 [57420/60000 (96%)]\tLoss: 1.567106\n",
      "Train Epoch: 10 [58410/60000 (97%)]\tLoss: 1.511942\n",
      "Train Epoch: 10 [59400/60000 (99%)]\tLoss: 1.546802\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 9724/10000 (97%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 1.540661\n",
      "Train Epoch: 11 [990/60000 (2%)]\tLoss: 1.527168\n",
      "Train Epoch: 11 [1980/60000 (3%)]\tLoss: 1.548596\n",
      "Train Epoch: 11 [2970/60000 (5%)]\tLoss: 1.526310\n",
      "Train Epoch: 11 [3960/60000 (7%)]\tLoss: 1.540285\n",
      "Train Epoch: 11 [4950/60000 (8%)]\tLoss: 1.489484\n",
      "Train Epoch: 11 [5940/60000 (10%)]\tLoss: 1.556989\n",
      "Train Epoch: 11 [6930/60000 (12%)]\tLoss: 1.531790\n",
      "Train Epoch: 11 [7920/60000 (13%)]\tLoss: 1.536682\n",
      "Train Epoch: 11 [8910/60000 (15%)]\tLoss: 1.523552\n",
      "Train Epoch: 11 [9900/60000 (16%)]\tLoss: 1.537483\n",
      "Train Epoch: 11 [10890/60000 (18%)]\tLoss: 1.484996\n",
      "Train Epoch: 11 [11880/60000 (20%)]\tLoss: 1.504880\n",
      "Train Epoch: 11 [12870/60000 (21%)]\tLoss: 1.574648\n",
      "Train Epoch: 11 [13860/60000 (23%)]\tLoss: 1.550295\n",
      "Train Epoch: 11 [14850/60000 (25%)]\tLoss: 1.568561\n",
      "Train Epoch: 11 [15840/60000 (26%)]\tLoss: 1.527201\n",
      "Train Epoch: 11 [16830/60000 (28%)]\tLoss: 1.529200\n",
      "Train Epoch: 11 [17820/60000 (30%)]\tLoss: 1.504128\n",
      "Train Epoch: 11 [18810/60000 (31%)]\tLoss: 1.496456\n",
      "Train Epoch: 11 [19800/60000 (33%)]\tLoss: 1.563133\n",
      "Train Epoch: 11 [20790/60000 (35%)]\tLoss: 1.550453\n",
      "Train Epoch: 11 [21780/60000 (36%)]\tLoss: 1.549877\n",
      "Train Epoch: 11 [22770/60000 (38%)]\tLoss: 1.549696\n",
      "Train Epoch: 11 [23760/60000 (40%)]\tLoss: 1.528783\n",
      "Train Epoch: 11 [24750/60000 (41%)]\tLoss: 1.529377\n",
      "Train Epoch: 11 [25740/60000 (43%)]\tLoss: 1.563449\n",
      "Train Epoch: 11 [26730/60000 (44%)]\tLoss: 1.547257\n",
      "Train Epoch: 11 [27720/60000 (46%)]\tLoss: 1.550635\n",
      "Train Epoch: 11 [28710/60000 (48%)]\tLoss: 1.499236\n",
      "Train Epoch: 11 [29700/60000 (49%)]\tLoss: 1.537904\n",
      "Train Epoch: 11 [30690/60000 (51%)]\tLoss: 1.520158\n",
      "Train Epoch: 11 [31680/60000 (53%)]\tLoss: 1.558233\n",
      "Train Epoch: 11 [32670/60000 (54%)]\tLoss: 1.540309\n",
      "Train Epoch: 11 [33660/60000 (56%)]\tLoss: 1.531059\n",
      "Train Epoch: 11 [34650/60000 (58%)]\tLoss: 1.503488\n",
      "Train Epoch: 11 [35640/60000 (59%)]\tLoss: 1.563108\n",
      "Train Epoch: 11 [36630/60000 (61%)]\tLoss: 1.553630\n",
      "Train Epoch: 11 [37620/60000 (63%)]\tLoss: 1.538107\n",
      "Train Epoch: 11 [38610/60000 (64%)]\tLoss: 1.536271\n",
      "Train Epoch: 11 [39600/60000 (66%)]\tLoss: 1.552721\n",
      "Train Epoch: 11 [40590/60000 (68%)]\tLoss: 1.597025\n",
      "Train Epoch: 11 [41580/60000 (69%)]\tLoss: 1.501638\n",
      "Train Epoch: 11 [42570/60000 (71%)]\tLoss: 1.529593\n",
      "Train Epoch: 11 [43560/60000 (72%)]\tLoss: 1.505377\n",
      "Train Epoch: 11 [44550/60000 (74%)]\tLoss: 1.497924\n",
      "Train Epoch: 11 [45540/60000 (76%)]\tLoss: 1.526525\n",
      "Train Epoch: 11 [46530/60000 (77%)]\tLoss: 1.519576\n",
      "Train Epoch: 11 [47520/60000 (79%)]\tLoss: 1.514981\n",
      "Train Epoch: 11 [48510/60000 (81%)]\tLoss: 1.550440\n",
      "Train Epoch: 11 [49500/60000 (82%)]\tLoss: 1.531430\n",
      "Train Epoch: 11 [50490/60000 (84%)]\tLoss: 1.519963\n",
      "Train Epoch: 11 [51480/60000 (86%)]\tLoss: 1.519316\n",
      "Train Epoch: 11 [52470/60000 (87%)]\tLoss: 1.538632\n",
      "Train Epoch: 11 [53460/60000 (89%)]\tLoss: 1.536963\n",
      "Train Epoch: 11 [54450/60000 (91%)]\tLoss: 1.523365\n",
      "Train Epoch: 11 [55440/60000 (92%)]\tLoss: 1.529564\n",
      "Train Epoch: 11 [56430/60000 (94%)]\tLoss: 1.492140\n",
      "Train Epoch: 11 [57420/60000 (96%)]\tLoss: 1.524470\n",
      "Train Epoch: 11 [58410/60000 (97%)]\tLoss: 1.516677\n",
      "Train Epoch: 11 [59400/60000 (99%)]\tLoss: 1.526337\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 9744/10000 (97%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 1.503753\n",
      "Train Epoch: 12 [990/60000 (2%)]\tLoss: 1.520258\n",
      "Train Epoch: 12 [1980/60000 (3%)]\tLoss: 1.520279\n",
      "Train Epoch: 12 [2970/60000 (5%)]\tLoss: 1.506491\n",
      "Train Epoch: 12 [3960/60000 (7%)]\tLoss: 1.559565\n",
      "Train Epoch: 12 [4950/60000 (8%)]\tLoss: 1.513610\n",
      "Train Epoch: 12 [5940/60000 (10%)]\tLoss: 1.500096\n",
      "Train Epoch: 12 [6930/60000 (12%)]\tLoss: 1.544666\n",
      "Train Epoch: 12 [7920/60000 (13%)]\tLoss: 1.527708\n",
      "Train Epoch: 12 [8910/60000 (15%)]\tLoss: 1.533176\n",
      "Train Epoch: 12 [9900/60000 (16%)]\tLoss: 1.546826\n",
      "Train Epoch: 12 [10890/60000 (18%)]\tLoss: 1.555836\n",
      "Train Epoch: 12 [11880/60000 (20%)]\tLoss: 1.493732\n",
      "Train Epoch: 12 [12870/60000 (21%)]\tLoss: 1.519339\n",
      "Train Epoch: 12 [13860/60000 (23%)]\tLoss: 1.558565\n",
      "Train Epoch: 12 [14850/60000 (25%)]\tLoss: 1.504253\n",
      "Train Epoch: 12 [15840/60000 (26%)]\tLoss: 1.566007\n",
      "Train Epoch: 12 [16830/60000 (28%)]\tLoss: 1.526745\n",
      "Train Epoch: 12 [17820/60000 (30%)]\tLoss: 1.528158\n",
      "Train Epoch: 12 [18810/60000 (31%)]\tLoss: 1.509930\n",
      "Train Epoch: 12 [19800/60000 (33%)]\tLoss: 1.563738\n",
      "Train Epoch: 12 [20790/60000 (35%)]\tLoss: 1.516831\n",
      "Train Epoch: 12 [21780/60000 (36%)]\tLoss: 1.519346\n",
      "Train Epoch: 12 [22770/60000 (38%)]\tLoss: 1.516144\n",
      "Train Epoch: 12 [23760/60000 (40%)]\tLoss: 1.528659\n",
      "Train Epoch: 12 [24750/60000 (41%)]\tLoss: 1.521474\n",
      "Train Epoch: 12 [25740/60000 (43%)]\tLoss: 1.525277\n",
      "Train Epoch: 12 [26730/60000 (44%)]\tLoss: 1.499834\n",
      "Train Epoch: 12 [27720/60000 (46%)]\tLoss: 1.496291\n",
      "Train Epoch: 12 [28710/60000 (48%)]\tLoss: 1.541511\n",
      "Train Epoch: 12 [29700/60000 (49%)]\tLoss: 1.504274\n",
      "Train Epoch: 12 [30690/60000 (51%)]\tLoss: 1.533177\n",
      "Train Epoch: 12 [31680/60000 (53%)]\tLoss: 1.504024\n",
      "Train Epoch: 12 [32670/60000 (54%)]\tLoss: 1.528573\n",
      "Train Epoch: 12 [33660/60000 (56%)]\tLoss: 1.536747\n",
      "Train Epoch: 12 [34650/60000 (58%)]\tLoss: 1.588171\n",
      "Train Epoch: 12 [35640/60000 (59%)]\tLoss: 1.581133\n",
      "Train Epoch: 12 [36630/60000 (61%)]\tLoss: 1.554934\n",
      "Train Epoch: 12 [37620/60000 (63%)]\tLoss: 1.535923\n",
      "Train Epoch: 12 [38610/60000 (64%)]\tLoss: 1.522506\n",
      "Train Epoch: 12 [39600/60000 (66%)]\tLoss: 1.512175\n",
      "Train Epoch: 12 [40590/60000 (68%)]\tLoss: 1.514889\n",
      "Train Epoch: 12 [41580/60000 (69%)]\tLoss: 1.505151\n",
      "Train Epoch: 12 [42570/60000 (71%)]\tLoss: 1.526962\n",
      "Train Epoch: 12 [43560/60000 (72%)]\tLoss: 1.537579\n",
      "Train Epoch: 12 [44550/60000 (74%)]\tLoss: 1.560981\n",
      "Train Epoch: 12 [45540/60000 (76%)]\tLoss: 1.539259\n",
      "Train Epoch: 12 [46530/60000 (77%)]\tLoss: 1.535861\n",
      "Train Epoch: 12 [47520/60000 (79%)]\tLoss: 1.544251\n",
      "Train Epoch: 12 [48510/60000 (81%)]\tLoss: 1.538898\n",
      "Train Epoch: 12 [49500/60000 (82%)]\tLoss: 1.545411\n",
      "Train Epoch: 12 [50490/60000 (84%)]\tLoss: 1.494851\n",
      "Train Epoch: 12 [51480/60000 (86%)]\tLoss: 1.516201\n",
      "Train Epoch: 12 [52470/60000 (87%)]\tLoss: 1.501771\n",
      "Train Epoch: 12 [53460/60000 (89%)]\tLoss: 1.500269\n",
      "Train Epoch: 12 [54450/60000 (91%)]\tLoss: 1.527828\n",
      "Train Epoch: 12 [55440/60000 (92%)]\tLoss: 1.546272\n",
      "Train Epoch: 12 [56430/60000 (94%)]\tLoss: 1.517944\n",
      "Train Epoch: 12 [57420/60000 (96%)]\tLoss: 1.506153\n",
      "Train Epoch: 12 [58410/60000 (97%)]\tLoss: 1.526070\n",
      "Train Epoch: 12 [59400/60000 (99%)]\tLoss: 1.510224\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 9754/10000 (98%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 1.526705\n",
      "Train Epoch: 13 [990/60000 (2%)]\tLoss: 1.483027\n",
      "Train Epoch: 13 [1980/60000 (3%)]\tLoss: 1.552199\n",
      "Train Epoch: 13 [2970/60000 (5%)]\tLoss: 1.523180\n",
      "Train Epoch: 13 [3960/60000 (7%)]\tLoss: 1.573868\n",
      "Train Epoch: 13 [4950/60000 (8%)]\tLoss: 1.494622\n",
      "Train Epoch: 13 [5940/60000 (10%)]\tLoss: 1.550323\n",
      "Train Epoch: 13 [6930/60000 (12%)]\tLoss: 1.558196\n",
      "Train Epoch: 13 [7920/60000 (13%)]\tLoss: 1.556444\n",
      "Train Epoch: 13 [8910/60000 (15%)]\tLoss: 1.494861\n",
      "Train Epoch: 13 [9900/60000 (16%)]\tLoss: 1.555948\n",
      "Train Epoch: 13 [10890/60000 (18%)]\tLoss: 1.525287\n",
      "Train Epoch: 13 [11880/60000 (20%)]\tLoss: 1.499335\n",
      "Train Epoch: 13 [12870/60000 (21%)]\tLoss: 1.488339\n",
      "Train Epoch: 13 [13860/60000 (23%)]\tLoss: 1.525278\n",
      "Train Epoch: 13 [14850/60000 (25%)]\tLoss: 1.494153\n",
      "Train Epoch: 13 [15840/60000 (26%)]\tLoss: 1.537543\n",
      "Train Epoch: 13 [16830/60000 (28%)]\tLoss: 1.546911\n",
      "Train Epoch: 13 [17820/60000 (30%)]\tLoss: 1.542866\n",
      "Train Epoch: 13 [18810/60000 (31%)]\tLoss: 1.591144\n",
      "Train Epoch: 13 [19800/60000 (33%)]\tLoss: 1.528131\n",
      "Train Epoch: 13 [20790/60000 (35%)]\tLoss: 1.528121\n",
      "Train Epoch: 13 [21780/60000 (36%)]\tLoss: 1.521032\n",
      "Train Epoch: 13 [22770/60000 (38%)]\tLoss: 1.516203\n",
      "Train Epoch: 13 [23760/60000 (40%)]\tLoss: 1.540283\n",
      "Train Epoch: 13 [24750/60000 (41%)]\tLoss: 1.525976\n",
      "Train Epoch: 13 [25740/60000 (43%)]\tLoss: 1.546866\n",
      "Train Epoch: 13 [26730/60000 (44%)]\tLoss: 1.547377\n",
      "Train Epoch: 13 [27720/60000 (46%)]\tLoss: 1.486837\n",
      "Train Epoch: 13 [28710/60000 (48%)]\tLoss: 1.512565\n",
      "Train Epoch: 13 [29700/60000 (49%)]\tLoss: 1.534123\n",
      "Train Epoch: 13 [30690/60000 (51%)]\tLoss: 1.542743\n",
      "Train Epoch: 13 [31680/60000 (53%)]\tLoss: 1.548160\n",
      "Train Epoch: 13 [32670/60000 (54%)]\tLoss: 1.517863\n",
      "Train Epoch: 13 [33660/60000 (56%)]\tLoss: 1.514671\n",
      "Train Epoch: 13 [34650/60000 (58%)]\tLoss: 1.536526\n",
      "Train Epoch: 13 [35640/60000 (59%)]\tLoss: 1.544800\n",
      "Train Epoch: 13 [36630/60000 (61%)]\tLoss: 1.511296\n",
      "Train Epoch: 13 [37620/60000 (63%)]\tLoss: 1.529680\n",
      "Train Epoch: 13 [38610/60000 (64%)]\tLoss: 1.506570\n",
      "Train Epoch: 13 [39600/60000 (66%)]\tLoss: 1.529346\n",
      "Train Epoch: 13 [40590/60000 (68%)]\tLoss: 1.525731\n",
      "Train Epoch: 13 [41580/60000 (69%)]\tLoss: 1.544146\n",
      "Train Epoch: 13 [42570/60000 (71%)]\tLoss: 1.526786\n",
      "Train Epoch: 13 [43560/60000 (72%)]\tLoss: 1.526039\n",
      "Train Epoch: 13 [44550/60000 (74%)]\tLoss: 1.557974\n",
      "Train Epoch: 13 [45540/60000 (76%)]\tLoss: 1.496669\n",
      "Train Epoch: 13 [46530/60000 (77%)]\tLoss: 1.511858\n",
      "Train Epoch: 13 [47520/60000 (79%)]\tLoss: 1.549941\n",
      "Train Epoch: 13 [48510/60000 (81%)]\tLoss: 1.554626\n",
      "Train Epoch: 13 [49500/60000 (82%)]\tLoss: 1.504048\n",
      "Train Epoch: 13 [50490/60000 (84%)]\tLoss: 1.504056\n",
      "Train Epoch: 13 [51480/60000 (86%)]\tLoss: 1.498139\n",
      "Train Epoch: 13 [52470/60000 (87%)]\tLoss: 1.512541\n",
      "Train Epoch: 13 [53460/60000 (89%)]\tLoss: 1.515163\n",
      "Train Epoch: 13 [54450/60000 (91%)]\tLoss: 1.495136\n",
      "Train Epoch: 13 [55440/60000 (92%)]\tLoss: 1.485206\n",
      "Train Epoch: 13 [56430/60000 (94%)]\tLoss: 1.509275\n",
      "Train Epoch: 13 [57420/60000 (96%)]\tLoss: 1.551716\n",
      "Train Epoch: 13 [58410/60000 (97%)]\tLoss: 1.541102\n",
      "Train Epoch: 13 [59400/60000 (99%)]\tLoss: 1.534750\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 9763/10000 (98%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 1.514249\n",
      "Train Epoch: 14 [990/60000 (2%)]\tLoss: 1.513698\n",
      "Train Epoch: 14 [1980/60000 (3%)]\tLoss: 1.520689\n",
      "Train Epoch: 14 [2970/60000 (5%)]\tLoss: 1.542081\n",
      "Train Epoch: 14 [3960/60000 (7%)]\tLoss: 1.503532\n",
      "Train Epoch: 14 [4950/60000 (8%)]\tLoss: 1.515884\n",
      "Train Epoch: 14 [5940/60000 (10%)]\tLoss: 1.500291\n",
      "Train Epoch: 14 [6930/60000 (12%)]\tLoss: 1.531098\n",
      "Train Epoch: 14 [7920/60000 (13%)]\tLoss: 1.544393\n",
      "Train Epoch: 14 [8910/60000 (15%)]\tLoss: 1.504328\n",
      "Train Epoch: 14 [9900/60000 (16%)]\tLoss: 1.518227\n",
      "Train Epoch: 14 [10890/60000 (18%)]\tLoss: 1.543189\n",
      "Train Epoch: 14 [11880/60000 (20%)]\tLoss: 1.516943\n",
      "Train Epoch: 14 [12870/60000 (21%)]\tLoss: 1.504453\n",
      "Train Epoch: 14 [13860/60000 (23%)]\tLoss: 1.514164\n",
      "Train Epoch: 14 [14850/60000 (25%)]\tLoss: 1.523433\n",
      "Train Epoch: 14 [15840/60000 (26%)]\tLoss: 1.548478\n",
      "Train Epoch: 14 [16830/60000 (28%)]\tLoss: 1.535196\n",
      "Train Epoch: 14 [17820/60000 (30%)]\tLoss: 1.534856\n",
      "Train Epoch: 14 [18810/60000 (31%)]\tLoss: 1.515991\n",
      "Train Epoch: 14 [19800/60000 (33%)]\tLoss: 1.563773\n",
      "Train Epoch: 14 [20790/60000 (35%)]\tLoss: 1.539299\n",
      "Train Epoch: 14 [21780/60000 (36%)]\tLoss: 1.495494\n",
      "Train Epoch: 14 [22770/60000 (38%)]\tLoss: 1.546404\n",
      "Train Epoch: 14 [23760/60000 (40%)]\tLoss: 1.529026\n",
      "Train Epoch: 14 [24750/60000 (41%)]\tLoss: 1.485285\n",
      "Train Epoch: 14 [25740/60000 (43%)]\tLoss: 1.492641\n",
      "Train Epoch: 14 [26730/60000 (44%)]\tLoss: 1.547678\n",
      "Train Epoch: 14 [27720/60000 (46%)]\tLoss: 1.535772\n",
      "Train Epoch: 14 [28710/60000 (48%)]\tLoss: 1.506964\n",
      "Train Epoch: 14 [29700/60000 (49%)]\tLoss: 1.515078\n",
      "Train Epoch: 14 [30690/60000 (51%)]\tLoss: 1.536995\n",
      "Train Epoch: 14 [31680/60000 (53%)]\tLoss: 1.513878\n",
      "Train Epoch: 14 [32670/60000 (54%)]\tLoss: 1.525955\n",
      "Train Epoch: 14 [33660/60000 (56%)]\tLoss: 1.521289\n",
      "Train Epoch: 14 [34650/60000 (58%)]\tLoss: 1.492653\n",
      "Train Epoch: 14 [35640/60000 (59%)]\tLoss: 1.572574\n",
      "Train Epoch: 14 [36630/60000 (61%)]\tLoss: 1.529101\n",
      "Train Epoch: 14 [37620/60000 (63%)]\tLoss: 1.525128\n",
      "Train Epoch: 14 [38610/60000 (64%)]\tLoss: 1.535133\n",
      "Train Epoch: 14 [39600/60000 (66%)]\tLoss: 1.529421\n",
      "Train Epoch: 14 [40590/60000 (68%)]\tLoss: 1.552983\n",
      "Train Epoch: 14 [41580/60000 (69%)]\tLoss: 1.511896\n",
      "Train Epoch: 14 [42570/60000 (71%)]\tLoss: 1.532181\n",
      "Train Epoch: 14 [43560/60000 (72%)]\tLoss: 1.483277\n",
      "Train Epoch: 14 [44550/60000 (74%)]\tLoss: 1.554765\n",
      "Train Epoch: 14 [45540/60000 (76%)]\tLoss: 1.548469\n",
      "Train Epoch: 14 [46530/60000 (77%)]\tLoss: 1.492707\n",
      "Train Epoch: 14 [47520/60000 (79%)]\tLoss: 1.532244\n",
      "Train Epoch: 14 [48510/60000 (81%)]\tLoss: 1.508756\n",
      "Train Epoch: 14 [49500/60000 (82%)]\tLoss: 1.501815\n",
      "Train Epoch: 14 [50490/60000 (84%)]\tLoss: 1.515506\n",
      "Train Epoch: 14 [51480/60000 (86%)]\tLoss: 1.503541\n",
      "Train Epoch: 14 [52470/60000 (87%)]\tLoss: 1.585591\n",
      "Train Epoch: 14 [53460/60000 (89%)]\tLoss: 1.501285\n",
      "Train Epoch: 14 [54450/60000 (91%)]\tLoss: 1.540667\n",
      "Train Epoch: 14 [55440/60000 (92%)]\tLoss: 1.514014\n",
      "Train Epoch: 14 [56430/60000 (94%)]\tLoss: 1.522242\n",
      "Train Epoch: 14 [57420/60000 (96%)]\tLoss: 1.515156\n",
      "Train Epoch: 14 [58410/60000 (97%)]\tLoss: 1.478192\n",
      "Train Epoch: 14 [59400/60000 (99%)]\tLoss: 1.540262\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 9768/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 15):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "data, target = test_data[1000]\n",
    "data = data.unsqueeze(0).to(device)\n",
    "output = model(data)\n",
    "\n",
    "predicition = output.argmax(dim=1, keepdim=True).item()\n",
    "print('Prediction: ', predicition)\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# trying out uploading your own image\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "image = Image.open('seven.jpg')\n",
    "\n",
    "image = image.convert('L') # for grayscale\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),  # Resize to the size your model expects\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize with the same mean and std used during training\n",
    "])\n",
    "\n",
    "image = transform(image)\n",
    "image = image.unsqueeze(0).to(device)\n",
    "\n",
    "output = model(image)\n",
    "\n",
    "predicition = output.argmax(dim=1, keepdim=True).item()\n",
    "print('Prediction: ', predicition)\n",
    "img = image.squeeze(0).squeeze(0).cpu().numpy()\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunit\\AppData\\Local\\Temp\\ipykernel_9640\\3749221115.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported to model.onnx\n"
     ]
    }
   ],
   "source": [
    "# save the model for onnx\n",
    "dummy_input = torch.randn(1, 1, 28, 28).to(device)\n",
    "onnx_model_path = 'model.onnx'\n",
    "torch.onnx.export(\n",
    "    model.to(device),                # Model to be exported\n",
    "    dummy_input,          # Dummy input tensor\n",
    "    onnx_model_path,      # Path to save the ONNX model\n",
    "    input_names=['input'],  # Input tensor name\n",
    "    output_names=['output'],  # Output tensor name\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}},  # Dynamic axes for variable batch size\n",
    "    opset_version=11      # ONNX opset version\n",
    ")\n",
    "\n",
    "print(f'Model exported to {onnx_model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model for streamlit\n",
    "scripted_model = torch.jit.script(model)\n",
    "scripted_model.save(\"mnist_model_scripted.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utdeeplearningclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
